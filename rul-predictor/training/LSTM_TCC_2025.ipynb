{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JUD15YmpHTH1",
        "outputId": "ee27a3f5-2df3-49c5-d393-4536004e16c9"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# RANDOM SEARCH DE HIPERPARÂMETROS INICIAL - LSTM (FD001 - C-MAPSS)\n",
        "# ============================================================\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ============================================================\n",
        "# Configurações iniciais\n",
        "# ============================================================\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# Leitura dos dados FD001\n",
        "# ============================================================\n",
        "base = \"/CMAPSSData/\"\n",
        "train = pd.read_csv(base + \"train_FD001.txt\", sep=r\"\\s+\", header=None)\n",
        "test  = pd.read_csv(base + \"test_FD001.txt\",  sep=r\"\\s+\", header=None)\n",
        "rul   = pd.read_csv(base + \"RUL_FD001.txt\",   sep=r\"\\s+\", header=None)\n",
        "print(f\"Train: {train.shape}, Test: {test.shape}, RULs: {rul.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# Preparação dos dados e RUL\n",
        "# ============================================================\n",
        "col_names = [\"unit_nr\", \"time_cycles\", \"setting_1\", \"setting_2\", \"setting_3\"] + [f\"s{i}\" for i in range(1, 22)]\n",
        "train.columns, test.columns = col_names, col_names\n",
        "\n",
        "rul_cap = 125\n",
        "rul_dict = {i+1: rul.iloc[i, 0] for i in range(len(rul))}\n",
        "\n",
        "def add_rul(df, is_test=False):\n",
        "    df = df.copy()\n",
        "    max_cycles = df.groupby(\"unit_nr\")[\"time_cycles\"].max().reset_index()\n",
        "    max_cycles.columns = [\"unit_nr\", \"max_cycle\"]\n",
        "    df = df.merge(max_cycles, on=\"unit_nr\", how=\"left\")\n",
        "    df[\"RUL\"] = df[\"max_cycle\"] - df[\"time_cycles\"]\n",
        "    if is_test:\n",
        "        df[\"RUL\"] += df[\"unit_nr\"].map(rul_dict)\n",
        "    df.drop(\"max_cycle\", axis=1, inplace=True)\n",
        "    df[\"RUL\"] = df[\"RUL\"].clip(upper=rul_cap)\n",
        "    return df\n",
        "\n",
        "train = add_rul(train)\n",
        "test = add_rul(test, is_test=True)\n",
        "\n",
        "# ============================================================\n",
        "# Remoção de sensores constantes\n",
        "# ============================================================\n",
        "const_cols = [c for c in train.columns if train[c].nunique() == 1]\n",
        "train.drop(columns=const_cols, inplace=True)\n",
        "test.drop(columns=const_cols, inplace=True)\n",
        "print(f\"Removidos sensores constantes: {const_cols}\")\n",
        "\n",
        "# ============================================================\n",
        "# Normalização por unidade\n",
        "# ============================================================\n",
        "feature_cols = [c for c in train.columns if c not in [\"unit_nr\", \"time_cycles\", \"RUL\"]]\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "def scale_by_unit(df):\n",
        "    scaled = []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u].copy()\n",
        "        unit_df[feature_cols] = scaler.fit_transform(unit_df[feature_cols])\n",
        "        scaled.append(unit_df)\n",
        "    return pd.concat(scaled, axis=0).reset_index(drop=True)\n",
        "\n",
        "train_scaled = scale_by_unit(train)\n",
        "test_scaled = scale_by_unit(test)\n",
        "print(\"Normalização concluída.\")\n",
        "\n",
        "# ============================================================\n",
        "# Função para criar janelas\n",
        "# ============================================================\n",
        "def make_sequences(df, window_size=30):\n",
        "    X, y, units = [], [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        features = unit_df[feature_cols].values\n",
        "        rul_vals = unit_df[\"RUL\"].values\n",
        "        for i in range(len(features) - window_size):\n",
        "            X.append(features[i:i+window_size])\n",
        "            y.append(rul_vals[i+window_size])\n",
        "            units.append(u)\n",
        "    return np.array(X), np.array(y), np.array(units)\n",
        "\n",
        "WINDOW_SIZE = 30\n",
        "X_all, y_all, units_all = make_sequences(train_scaled, WINDOW_SIZE)\n",
        "print(f\"Janelas treino/validação: {X_all.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# Divisão temporal 80/20 por unidade\n",
        "# ============================================================\n",
        "unique_units = np.unique(units_all)\n",
        "n_train = int(len(unique_units) * 0.8)\n",
        "train_units = unique_units[:n_train]\n",
        "val_units = unique_units[n_train:]\n",
        "\n",
        "mask_train = np.isin(units_all, train_units)\n",
        "mask_val   = np.isin(units_all, val_units)\n",
        "\n",
        "X_train, y_train = X_all[mask_train], y_all[mask_train]\n",
        "X_val,   y_val   = X_all[mask_val],   y_all[mask_val]\n",
        "\n",
        "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_val:   {X_val.shape}, y_val:   {y_val.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# Função construtora do modelo\n",
        "# ============================================================\n",
        "def build_model(n_timesteps, n_features, lstm1=64, lstm2=32, dropout=0.2, lr=1e-3):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(n_timesteps, n_features)),\n",
        "        layers.LSTM(lstm1, return_sequences=True),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.LSTM(lstm2),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(1, activation=\"linear\")\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss=\"mse\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "                 keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# Random Search de hiperparâmetros\n",
        "# ============================================================\n",
        "param_grid = {\n",
        "    \"lstm1\": [32, 64, 128],\n",
        "    \"lstm2\": [16, 32, 64],\n",
        "    \"dropout\": [0.1, 0.2, 0.3],\n",
        "    \"lr\": [1e-2, 1e-3, 5e-4, 1e-4],\n",
        "    \"batch_size\": [64, 128, 256]\n",
        "}\n",
        "\n",
        "N_TRIALS = 20\n",
        "results = []\n",
        "n_timesteps, n_features = X_train.shape[1], X_train.shape[2]\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "reduce_lr  = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "\n",
        "for i in range(N_TRIALS):\n",
        "    params = {k: random.choice(v) for k, v in param_grid.items()}\n",
        "    print(f\"\\n Rodando combinação {i+1}/{N_TRIALS}: {params}\")\n",
        "\n",
        "    model = build_model(n_timesteps, n_features,\n",
        "                        lstm1=params[\"lstm1\"],\n",
        "                        lstm2=params[\"lstm2\"],\n",
        "                        dropout=params[\"dropout\"],\n",
        "                        lr=params[\"lr\"])\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=80,\n",
        "        batch_size=params[\"batch_size\"],\n",
        "        callbacks=[early_stop, reduce_lr],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val, verbose=0).flatten()\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "\n",
        "    results.append({**params, \"mae\": mae, \"rmse\": rmse})\n",
        "    print(f\"MAE={mae:.2f} | RMSE={rmse:.2f}\")\n",
        "\n",
        "# ============================================================\n",
        "# Resultados consolidados\n",
        "# ============================================================\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"rmse\").reset_index(drop=True)\n",
        "print(\"\\n===== RESULTADOS (ordenados por RMSE) =====\")\n",
        "display(results_df)\n",
        "\n",
        "# ============================================================\n",
        "# Melhor configuração\n",
        "# ============================================================\n",
        "best_params = results_df.iloc[0].to_dict()\n",
        "print(\"\\n Melhor configuração encontrada:\")\n",
        "for k, v in best_params.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N8nFZjYabIMz",
        "outputId": "2bfc7cc9-537d-454e-9288-2f2071ce1e13"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MODELO LSTM INICIAL - (FD001 - C-MAPSS)\n",
        "# Modelo inicial: normalização por unidade\n",
        "# ============================================================\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURAÇÕES INICIAIS\n",
        "# ============================================================\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# LEITURA DOS DADOS FD001\n",
        "# ============================================================\n",
        "base = \"CMAPSSData/\"\n",
        "train = pd.read_csv(base + \"train_FD001.txt\", sep=r\"\\s+\", header=None)\n",
        "test  = pd.read_csv(base + \"test_FD001.txt\",  sep=r\"\\s+\", header=None)\n",
        "rul   = pd.read_csv(base + \"RUL_FD001.txt\",   sep=r\"\\s+\", header=None)\n",
        "\n",
        "col_names = [\"unit_nr\", \"time_cycles\", \"setting_1\", \"setting_2\", \"setting_3\"] \\\n",
        "            + [f\"s{i}\" for i in range(1, 22)]\n",
        "train.columns = col_names\n",
        "test.columns  = col_names\n",
        "\n",
        "print(\"Train:\", train.shape, \"Test:\", test.shape)\n",
        "\n",
        "# ============================================================\n",
        "# CÁLCULO DO RUL\n",
        "# ============================================================\n",
        "rul_cap = 125\n",
        "rul_dict = {i+1: rul.iloc[i, 0] for i in range(len(rul))}\n",
        "\n",
        "def add_rul(df, is_test=False):\n",
        "    df = df.copy()\n",
        "    max_cycles = df.groupby(\"unit_nr\")[\"time_cycles\"].max().reset_index()\n",
        "    max_cycles.columns = [\"unit_nr\", \"max_cycle\"]\n",
        "    df = df.merge(max_cycles, on=\"unit_nr\", how=\"left\")\n",
        "    df[\"RUL\"] = df[\"max_cycle\"] - df[\"time_cycles\"]\n",
        "\n",
        "    if is_test:\n",
        "        df[\"RUL\"] += df[\"unit_nr\"].map(rul_dict)\n",
        "\n",
        "    df.drop(\"max_cycle\", axis=1, inplace=True)\n",
        "    df[\"RUL\"] = df[\"RUL\"].clip(upper=rul_cap)\n",
        "    return df\n",
        "\n",
        "train = add_rul(train)\n",
        "test  = add_rul(test, is_test=True)\n",
        "\n",
        "# ============================================================\n",
        "# REMOÇÃO DOS SENSORES CONSTANTES\n",
        "# ============================================================\n",
        "const_cols = [c for c in train.columns if train[c].nunique() == 1]\n",
        "train.drop(columns=const_cols, inplace=True)\n",
        "test.drop(columns=const_cols, inplace=True)\n",
        "\n",
        "print(\"Sensores removidos:\", const_cols)\n",
        "\n",
        "# ============================================================\n",
        "# NORMALIZAÇÃO CONSISTENTE ENTRE TREINO E TESTE\n",
        "# ============================================================\n",
        "\n",
        "feature_cols = [c for c in train.columns if c not in [\"unit_nr\", \"time_cycles\", \"RUL\"]]\n",
        "\n",
        "# ARMAZENAR UM SCALER POR MOTOR DO TREINO\n",
        "train_scalers = {}\n",
        "\n",
        "def scale_train(df):\n",
        "    scaled = []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u].copy()\n",
        "        scaler = MinMaxScaler()\n",
        "        unit_df[feature_cols] = scaler.fit_transform(unit_df[feature_cols])\n",
        "        train_scalers[u] = scaler\n",
        "        scaled.append(unit_df)\n",
        "    return pd.concat(scaled).reset_index(drop=True)\n",
        "\n",
        "def scale_test(df):\n",
        "    scaled = []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u].copy()\n",
        "\n",
        "        if u not in train_scalers:\n",
        "            raise ValueError(f\"Motor {u} não existe no treino!\")\n",
        "\n",
        "        scaler = train_scalers[u]\n",
        "        unit_df[feature_cols] = scaler.transform(unit_df[feature_cols])\n",
        "\n",
        "        scaled.append(unit_df)\n",
        "    return pd.concat(scaled).reset_index(drop=True)\n",
        "\n",
        "train_scaled = scale_train(train)\n",
        "test_scaled  = scale_test(test)\n",
        "\n",
        "print(\"Normalização consistente concluída.\")\n",
        "\n",
        "# ============================================================\n",
        "# CRIAÇÃO DE JANELAS (TRAIN / VAL)\n",
        "# ============================================================\n",
        "def make_sequences(df, window_size=30):\n",
        "    X, y, units = [], [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "\n",
        "        for i in range(len(feat) - window_size):\n",
        "            X.append(feat[i:i+window_size])\n",
        "            y.append(rul[i+window_size])\n",
        "            units.append(u)\n",
        "\n",
        "    return np.array(X), np.array(y), np.array(units)\n",
        "\n",
        "WINDOW = 30\n",
        "X_all, y_all, units_all = make_sequences(train_scaled, WINDOW)\n",
        "\n",
        "# ============================================================\n",
        "# DIVISÃO TEMPORAL 80/20 POR UNIDADE\n",
        "# ============================================================\n",
        "unique_units = np.unique(units_all)\n",
        "n_train = int(0.8 * len(unique_units))\n",
        "train_units = unique_units[:n_train]\n",
        "val_units   = unique_units[n_train:]\n",
        "\n",
        "mask_train = np.isin(units_all, train_units)\n",
        "mask_val   = np.isin(units_all, val_units)\n",
        "\n",
        "X_train, y_train = X_all[mask_train], y_all[mask_train]\n",
        "X_val,   y_val   = X_all[mask_val],   y_all[mask_val]\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "\n",
        "# ============================================================\n",
        "# MODELO LSTM INICIAL\n",
        "# ============================================================\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(WINDOW, len(feature_cols))),\n",
        "        layers.LSTM(64, return_sequences=True),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.LSTM(64),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(1, activation=\"linear\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"mse\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
        "        metrics=[\n",
        "            keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "            keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# ============================================================\n",
        "# TREINO FINAL\n",
        "# ============================================================\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "reduce_lr  = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=80,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TESTE FINAL — ÚLTIMA JANELA POR MOTOR\n",
        "# ============================================================\n",
        "def make_sequences_test(df, window_size=30):\n",
        "    X, y = [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "\n",
        "        X.append(feat[-window_size:])\n",
        "        y.append(rul[-1])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_test, y_test = make_sequences_test(test_scaled)\n",
        "\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(\"\\n=========== RESULTADO FINAL (FD001 - ÚLTIMA JANELA) ===========\")\n",
        "print(f\"MAE  = {mae:.2f} ciclos\")\n",
        "print(f\"RMSE = {rmse:.2f} ciclos\")\n",
        "\n",
        "# ============================================================\n",
        "# DISPERSÃO\n",
        "# ============================================================\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([0,125], [0,125], \"r--\", label=\"Ideal\")\n",
        "plt.xlabel(\"RUL Real\")\n",
        "plt.ylabel(\"RUL Previsto\")\n",
        "plt.title(\"FD001 - Última Janela por Motor\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0QVGkYhgM1kd",
        "outputId": "19f510f5-f633-4165-ee12-e83121c9fe2a"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Primeira Deep LSTM + Residual Connections + Feature Engineering\n",
        "# ============================================================\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURAÇÕES INICIAIS\n",
        "# ============================================================\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# LEITURA DOS DADOS FD001\n",
        "# ============================================================\n",
        "base = \"CMAPSSData/\"\n",
        "train = pd.read_csv(base + \"train_FD001.txt\", sep=r\"\\s+\", header=None)\n",
        "test  = pd.read_csv(base + \"test_FD001.txt\",  sep=r\"\\s+\", header=None)\n",
        "rul   = pd.read_csv(base + \"RUL_FD001.txt\",   sep=r\"\\s+\", header=None)\n",
        "\n",
        "col_names = [\"unit_nr\", \"time_cycles\", \"setting_1\", \"setting_2\", \"setting_3\"] \\\n",
        "    + [f\"s{i}\" for i in range(1, 22)]\n",
        "train.columns = col_names\n",
        "test.columns  = col_names\n",
        "\n",
        "print(\"Train:\", train.shape, \"Test:\", test.shape)\n",
        "\n",
        "# ============================================================\n",
        "# RUL COM LIMITE (125)\n",
        "# ============================================================\n",
        "rul_cap = 125\n",
        "rul_dict = {i+1: rul.iloc[i, 0] for i in range(len(rul))}\n",
        "\n",
        "def add_rul(df, is_test=False):\n",
        "    df = df.copy()\n",
        "    m = df.groupby(\"unit_nr\")[\"time_cycles\"].max().reset_index()\n",
        "    m.columns = [\"unit_nr\", \"max_cycle\"]\n",
        "    df = df.merge(m, on=\"unit_nr\", how=\"left\")\n",
        "    df[\"RUL\"] = df[\"max_cycle\"] - df[\"time_cycles\"]\n",
        "    if is_test:\n",
        "        df[\"RUL\"] += df[\"unit_nr\"].map(rul_dict)\n",
        "    df[\"RUL\"] = df[\"RUL\"].clip(upper=rul_cap)\n",
        "    df.drop(\"max_cycle\", axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "train = add_rul(train)\n",
        "test  = add_rul(test, is_test=True)\n",
        "\n",
        "# ============================================================\n",
        "# REMOVE SENSORES CONSTANTES\n",
        "# ============================================================\n",
        "const_cols = [c for c in train.columns if train[c].nunique() == 1]\n",
        "train.drop(columns=const_cols, inplace=True)\n",
        "test.drop(columns=const_cols, inplace=True)\n",
        "print(\"Sensores removidos:\", const_cols)\n",
        "\n",
        "# ============================================================\n",
        "# FEATURE ENGINEERING\n",
        "# ============================================================\n",
        "def add_features(df):\n",
        "    df = df.copy()\n",
        "    sensor_cols = [c for c in df.columns if c.startswith(\"s\")]\n",
        "    for s in sensor_cols:\n",
        "        df[f\"{s}_mean5\"] = df.groupby(\"unit_nr\")[s].rolling(5, min_periods=1).mean().reset_index(0,drop=True)\n",
        "        df[f\"{s}_std5\"]  = df.groupby(\"unit_nr\")[s].rolling(5, min_periods=1).std().reset_index(0,drop=True).fillna(0)\n",
        "        df[f\"{s}_slope\"] = df.groupby(\"unit_nr\")[s].diff().fillna(0)\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test  = add_features(test)\n",
        "\n",
        "# ============================================================\n",
        "# NORMALIZAÇÃO GLOBAL POR FEATURE\n",
        "# ============================================================\n",
        "feature_cols = [c for c in train.columns if c not in [\"unit_nr\", \"time_cycles\", \"RUL\"]]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
        "test[feature_cols]  = scaler.transform(test[feature_cols])\n",
        "\n",
        "# ============================================================\n",
        "# CRIAÇÃO DAS JANELAS (30)\n",
        "# ============================================================\n",
        "def make_sequences(df, window=30):\n",
        "    X, y, units = [], [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "        for i in range(len(feat) - window):\n",
        "            X.append(feat[i:i+window])\n",
        "            y.append(rul[i+window])\n",
        "            units.append(u)\n",
        "    return np.array(X), np.array(y), np.array(units)\n",
        "\n",
        "WINDOW = 30\n",
        "X_all, y_all, units_all = make_sequences(train)\n",
        "\n",
        "# ============================================================\n",
        "# DIVISÃO TEMPORAL 80/20 POR MOTOR\n",
        "# ============================================================\n",
        "unique_units = np.unique(units_all)\n",
        "n_train = int(0.8 * len(unique_units))\n",
        "train_units = unique_units[:n_train]\n",
        "val_units   = unique_units[n_train:]\n",
        "\n",
        "mask_train = np.isin(units_all, train_units)\n",
        "mask_val   = np.isin(units_all, val_units)\n",
        "\n",
        "X_train, y_train = X_all[mask_train], y_all[mask_train]\n",
        "X_val,   y_val   = X_all[mask_val],   y_all[mask_val]\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "\n",
        "# ============================================================\n",
        "# MODELO LSTM PURO\n",
        "# Residual Connections + Deep LSTM\n",
        "# ============================================================\n",
        "\n",
        "def build_residual_lstm(n_timesteps, n_features):\n",
        "    inp = layers.Input(shape=(n_timesteps, n_features))\n",
        "\n",
        "    # LSTM 1\n",
        "    x1 = layers.LSTM(128, return_sequences=True)(inp)\n",
        "    x1 = layers.Dropout(0.2)(x1)\n",
        "\n",
        "    # LSTM 2\n",
        "    x2 = layers.LSTM(128, return_sequences=True)(x1)\n",
        "    x2 = layers.Dropout(0.2)(x2)\n",
        "\n",
        "    # Residual 1 (x1 + x2)\n",
        "    res1 = layers.add([x1, x2])\n",
        "\n",
        "    # LSTM 3\n",
        "    x3 = layers.LSTM(64)(res1)\n",
        "    x3 = layers.Dropout(0.2)(x3)\n",
        "\n",
        "    # DENSE FINAL\n",
        "    out = layers.Dense(1, activation=\"relu\")(x3)\n",
        "\n",
        "    model = keras.Model(inputs=inp, outputs=out)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"mse\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        metrics=[\n",
        "            keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "            keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_residual_lstm(WINDOW, len(feature_cols))\n",
        "model.summary()\n",
        "\n",
        "# ============================================================\n",
        "# TREINO FINAL\n",
        "# ============================================================\n",
        "early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
        "reduce = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-6)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=120,\n",
        "    batch_size=64,\n",
        "    callbacks=[early, reduce],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TESTE – ÚLTIMA JANELA\n",
        "# ============================================================\n",
        "def make_test_last(df, window=30):\n",
        "    X, y = [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "        X.append(feat[-window:])\n",
        "        y.append(rul[-1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_test, y_test = make_test_last(test)\n",
        "pred = model.predict(X_test).flatten()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "\n",
        "print(\"\\n=========== RESULTADO – ÚLTIMA JANELA ===========\")\n",
        "print(f\"MAE  = {mae:.2f}\")\n",
        "print(f\"RMSE = {rmse:.2f}\")\n",
        "\n",
        "# ============================================================\n",
        "# DISPERSÃO\n",
        "# ============================================================\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, pred, alpha=0.5)\n",
        "plt.plot([0,125],[0,125],'r--')\n",
        "plt.xlabel(\"RUL real\")\n",
        "plt.ylabel(\"RUL previsto\")\n",
        "plt.title(\"LSTM Residual – Última Janela\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUxjMe4f4vhA",
        "outputId": "42a6215d-db44-4705-f180-b9b8eddcd9fd"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# RANDOM SEARCH – MODELO LSTM RESIDUAL – FD001\n",
        "# Mesma arquitetura, apenas hiperparâmetros variando\n",
        "# ============================================================\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURAÇÕES INICIAIS\n",
        "# ============================================================\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# LEITURA DOS DADOS FD001\n",
        "# ============================================================\n",
        "base = \"CMAPSSData/\"\n",
        "train = pd.read_csv(base + \"train_FD001.txt\", sep=r\"\\s+\", header=None)\n",
        "test  = pd.read_csv(base + \"test_FD001.txt\",  sep=r\"\\s+\", header=None)\n",
        "rul   = pd.read_csv(base + \"RUL_FD001.txt\",   sep=r\"\\s+\", header=None)\n",
        "\n",
        "col_names = [\"unit_nr\", \"time_cycles\", \"setting_1\", \"setting_2\", \"setting_3\"] \\\n",
        "    + [f\"s{i}\" for i in range(1, 22)]\n",
        "train.columns = col_names\n",
        "test.columns  = col_names\n",
        "\n",
        "print(\"Train:\", train.shape, \"Test:\", test.shape)\n",
        "\n",
        "# ============================================================\n",
        "# RUL COM CAP (125)\n",
        "# ============================================================\n",
        "rul_cap = 125\n",
        "rul_dict = {i+1: rul.iloc[i, 0] for i in range(len(rul))}\n",
        "\n",
        "def add_rul(df, is_test=False):\n",
        "    df = df.copy()\n",
        "    m = df.groupby(\"unit_nr\")[\"time_cycles\"].max().reset_index()\n",
        "    m.columns = [\"unit_nr\", \"max_cycle\"]\n",
        "    df = df.merge(m, on=\"unit_nr\", how=\"left\")\n",
        "    df[\"RUL\"] = df[\"max_cycle\"] - df[\"time_cycles\"]\n",
        "    if is_test:\n",
        "        df[\"RUL\"] += df[\"unit_nr\"].map(rul_dict)\n",
        "    df[\"RUL\"] = df[\"RUL\"].clip(upper=rul_cap)\n",
        "    df.drop(\"max_cycle\", axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "train = add_rul(train)\n",
        "test  = add_rul(test, is_test=True)\n",
        "\n",
        "# ============================================================\n",
        "# REMOVE SENSORES CONSTANTES\n",
        "# ============================================================\n",
        "const_cols = [c for c in train.columns if train[c].nunique() == 1]\n",
        "train.drop(columns=const_cols, inplace=True)\n",
        "test.drop(columns=const_cols, inplace=True)\n",
        "print(\"Sensores removidos:\", const_cols)\n",
        "\n",
        "# ============================================================\n",
        "# FEATURE ENGINEERING\n",
        "# ============================================================\n",
        "def add_features(df):\n",
        "    df = df.copy()\n",
        "    sensor_cols = [c for c in df.columns if c.startswith(\"s\")]\n",
        "    for s in sensor_cols:\n",
        "        df[f\"{s}_mean5\"] = df.groupby(\"unit_nr\")[s].rolling(5, min_periods=1).mean().reset_index(0,drop=True)\n",
        "        df[f\"{s}_std5\"]  = df.groupby(\"unit_nr\")[s].rolling(5, min_periods=1).std().reset_index(0,drop=True).fillna(0)\n",
        "        df[f\"{s}_slope\"] = df.groupby(\"unit_nr\")[s].diff().fillna(0)\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test  = add_features(test)\n",
        "\n",
        "# ============================================================\n",
        "# NORMALIZAÇÃO GLOBAL POR FEATURE\n",
        "# ============================================================\n",
        "feature_cols = [c for c in train.columns if c not in [\"unit_nr\", \"time_cycles\", \"RUL\"]]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
        "test[feature_cols]  = scaler.transform(test[feature_cols])\n",
        "\n",
        "# ============================================================\n",
        "# CRIAÇÃO DAS JANELAS 30\n",
        "# ============================================================\n",
        "def make_sequences(df, window=30):\n",
        "    X, y, units = [], [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "        for i in range(len(feat) - window):\n",
        "            X.append(feat[i:i+window])\n",
        "            y.append(rul[i+window])\n",
        "            units.append(u)\n",
        "    return np.array(X), np.array(y), np.array(units)\n",
        "\n",
        "WINDOW = 30\n",
        "X_all, y_all, units_all = make_sequences(train)\n",
        "\n",
        "# ============================================================\n",
        "# DIVISÃO TEMPORAL 80/20 POR MOTOR\n",
        "# ============================================================\n",
        "unique_units = np.unique(units_all)\n",
        "n_train = int(0.8 * len(unique_units))\n",
        "train_units = unique_units[:n_train]\n",
        "val_units   = unique_units[n_train:]\n",
        "\n",
        "mask_train = np.isin(units_all, train_units)\n",
        "mask_val   = np.isin(units_all, val_units)\n",
        "\n",
        "X_train, y_train = X_all[mask_train], y_all[mask_train]\n",
        "X_val,   y_val   = X_all[mask_val],   y_all[mask_val]\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "\n",
        "# ============================================================\n",
        "# MODELO LSTM RESIDUAL\n",
        "# ============================================================\n",
        "def build_model(lstm_units, dropout_rate, lr):\n",
        "\n",
        "    inp = layers.Input(shape=(WINDOW, len(feature_cols)))\n",
        "\n",
        "    # LSTM 1\n",
        "    x1 = layers.LSTM(lstm_units, return_sequences=True)(inp)\n",
        "    x1 = layers.Dropout(dropout_rate)(x1)\n",
        "\n",
        "    # LSTM 2\n",
        "    x2 = layers.LSTM(lstm_units, return_sequences=True)(x1)\n",
        "    x2 = layers.Dropout(dropout_rate)(x2)\n",
        "\n",
        "    # Residual\n",
        "    res1 = layers.add([x1, x2])\n",
        "\n",
        "    # LSTM 3\n",
        "    x3 = layers.LSTM(lstm_units // 2)(res1)\n",
        "    x3 = layers.Dropout(dropout_rate)(x3)\n",
        "\n",
        "    out = layers.Dense(1, activation=\"relu\")(x3)\n",
        "\n",
        "    model = keras.Model(inputs=inp, outputs=out)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"mse\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=[keras.metrics.MeanAbsoluteError(),\n",
        "                 keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# RANDOM SEARCH CONFIG\n",
        "# ============================================================\n",
        "param_grid = {\n",
        "    \"lstm_units\": [96, 128, 160],\n",
        "    \"dropout_rate\": [0.1, 0.2, 0.3],\n",
        "    \"lr\": [1e-3, 7e-4, 5e-4],\n",
        "    \"batch_size\": [32, 64, 128]\n",
        "}\n",
        "\n",
        "N_TRIALS = 8\n",
        "results = []\n",
        "\n",
        "early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True)\n",
        "reduce = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-6)\n",
        "\n",
        "# ============================================================\n",
        "# RANDOM SEARCH LOOP\n",
        "# ============================================================\n",
        "for i in range(N_TRIALS):\n",
        "    params = {k: random.choice(v) for k,v in param_grid.items()}\n",
        "    print(f\"\\n Testando combinação {i+1}/{N_TRIALS}: {params}\")\n",
        "\n",
        "    model = build_model(\n",
        "        lstm_units=params[\"lstm_units\"],\n",
        "        dropout_rate=params[\"dropout_rate\"],\n",
        "        lr=params[\"lr\"]\n",
        "    )\n",
        "\n",
        "    hist = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=80,\n",
        "        batch_size=params[\"batch_size\"],\n",
        "        callbacks=[early, reduce],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    pred_val = model.predict(X_val, verbose=0).flatten()\n",
        "    mae = mean_absolute_error(y_val, pred_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, pred_val))\n",
        "\n",
        "    params[\"mae\"] = mae\n",
        "    params[\"rmse\"] = rmse\n",
        "    results.append(params)\n",
        "\n",
        "    print(f\"MAE={mae:.2f} | RMSE={rmse:.2f}\")\n",
        "\n",
        "# ============================================================\n",
        "# RESULTADOS\n",
        "# ============================================================\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"rmse\")\n",
        "print(\"\\n===== RESULTADOS =====\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8KtiqQOOxbwo",
        "outputId": "ff01558f-38d8-41af-c27f-351dba0d7f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (20631, 26) Test: (13096, 26)\n",
            "Sensores removidos: ['setting_3', 's1', 's5', 's10', 's16', 's18', 's19']\n",
            "X_train: (13738, 30, 68) X_val: (3893, 30, 68)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">63,360</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,112</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,840</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m68\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │     \u001b[38;5;34m63,360\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │     \u001b[38;5;34m74,112\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │     \u001b[38;5;34m27,840\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m49\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,361</span> (645.94 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m165,361\u001b[0m (645.94 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,361</span> (645.94 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m165,361\u001b[0m (645.94 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 8011.1675 - mae: 79.2008 - rmse: 89.5051 - val_loss: 8908.4268 - val_mae: 84.5970 - val_rmse: 94.3845 - learning_rate: 0.0010\n",
            "Epoch 2/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 6001.0098 - mae: 66.3023 - rmse: 77.4662 - val_loss: 4143.2065 - val_mae: 55.6323 - val_rmse: 64.3677 - learning_rate: 0.0010\n",
            "Epoch 3/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 2878.3367 - mae: 46.0121 - rmse: 53.6501 - val_loss: 2653.0156 - val_mae: 45.6045 - val_rmse: 51.5074 - learning_rate: 0.0010\n",
            "Epoch 4/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 2101.5825 - mae: 40.4364 - rmse: 45.8430 - val_loss: 2093.8562 - val_mae: 41.2830 - val_rmse: 45.7587 - learning_rate: 0.0010\n",
            "Epoch 5/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1836.1527 - mae: 38.2084 - rmse: 42.8504 - val_loss: 1885.1722 - val_mae: 39.3380 - val_rmse: 43.4186 - learning_rate: 0.0010\n",
            "Epoch 6/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1770.0966 - mae: 37.4615 - rmse: 42.0725 - val_loss: 1813.6204 - val_mae: 38.5081 - val_rmse: 42.5866 - learning_rate: 0.0010\n",
            "Epoch 7/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1753.7512 - mae: 37.2008 - rmse: 41.8778 - val_loss: 1791.8517 - val_mae: 38.2036 - val_rmse: 42.3303 - learning_rate: 0.0010\n",
            "Epoch 8/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1757.5956 - mae: 37.1700 - rmse: 41.9237 - val_loss: 1785.0728 - val_mae: 38.0981 - val_rmse: 42.2501 - learning_rate: 0.0010\n",
            "Epoch 9/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1746.6667 - mae: 37.0279 - rmse: 41.7931 - val_loss: 1782.6567 - val_mae: 38.0583 - val_rmse: 42.2215 - learning_rate: 0.0010\n",
            "Epoch 10/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1748.1643 - mae: 37.0379 - rmse: 41.8111 - val_loss: 1782.3160 - val_mae: 38.0529 - val_rmse: 42.2175 - learning_rate: 0.0010\n",
            "Epoch 11/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1754.7299 - mae: 37.0997 - rmse: 41.8895 - val_loss: 1782.6251 - val_mae: 38.0578 - val_rmse: 42.2211 - learning_rate: 0.0010\n",
            "Epoch 12/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1755.4839 - mae: 37.0965 - rmse: 41.8985 - val_loss: 1782.1379 - val_mae: 38.0500 - val_rmse: 42.2154 - learning_rate: 0.0010\n",
            "Epoch 13/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1750.7946 - mae: 37.0584 - rmse: 41.8425 - val_loss: 1783.1384 - val_mae: 38.0661 - val_rmse: 42.2272 - learning_rate: 0.0010\n",
            "Epoch 14/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 1755.4763 - mae: 37.1048 - rmse: 41.8984 - val_loss: 1782.4980 - val_mae: 38.0558 - val_rmse: 42.2196 - learning_rate: 0.0010\n",
            "Epoch 15/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 990.8850 - mae: 25.9508 - rmse: 31.4783 - val_loss: 566.0721 - val_mae: 20.3115 - val_rmse: 23.7923 - learning_rate: 0.0010\n",
            "Epoch 16/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 338.5841 - mae: 15.0608 - rmse: 18.4007 - val_loss: 329.0794 - val_mae: 14.7513 - val_rmse: 18.1405 - learning_rate: 0.0010\n",
            "Epoch 17/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 240.9546 - mae: 12.3375 - rmse: 15.5227 - val_loss: 288.1199 - val_mae: 13.0166 - val_rmse: 16.9741 - learning_rate: 0.0010\n",
            "Epoch 18/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 211.2559 - mae: 11.1403 - rmse: 14.5346 - val_loss: 195.4191 - val_mae: 10.6729 - val_rmse: 13.9792 - learning_rate: 0.0010\n",
            "Epoch 19/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 199.0609 - mae: 10.5883 - rmse: 14.1089 - val_loss: 209.0391 - val_mae: 10.5923 - val_rmse: 14.4582 - learning_rate: 0.0010\n",
            "Epoch 20/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 194.5394 - mae: 10.3627 - rmse: 13.9477 - val_loss: 199.0466 - val_mae: 10.3430 - val_rmse: 14.1084 - learning_rate: 0.0010\n",
            "Epoch 21/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 191.8317 - mae: 10.2349 - rmse: 13.8503 - val_loss: 174.6262 - val_mae: 9.7546 - val_rmse: 13.2146 - learning_rate: 0.0010\n",
            "Epoch 22/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 188.8202 - mae: 10.1227 - rmse: 13.7412 - val_loss: 214.1921 - val_mae: 10.3953 - val_rmse: 14.6353 - learning_rate: 0.0010\n",
            "Epoch 23/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 184.4758 - mae: 10.0141 - rmse: 13.5822 - val_loss: 245.3215 - val_mae: 11.6288 - val_rmse: 15.6627 - learning_rate: 0.0010\n",
            "Epoch 24/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 183.1084 - mae: 9.9322 - rmse: 13.5318 - val_loss: 188.4296 - val_mae: 9.9619 - val_rmse: 13.7270 - learning_rate: 0.0010\n",
            "Epoch 25/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 177.7227 - mae: 9.8376 - rmse: 13.3313 - val_loss: 186.5256 - val_mae: 10.0690 - val_rmse: 13.6574 - learning_rate: 0.0010\n",
            "Epoch 26/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 176.6248 - mae: 9.7520 - rmse: 13.2900 - val_loss: 181.0619 - val_mae: 9.9820 - val_rmse: 13.4559 - learning_rate: 0.0010\n",
            "Epoch 27/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 170.2923 - mae: 9.5872 - rmse: 13.0496 - val_loss: 189.8338 - val_mae: 9.9506 - val_rmse: 13.7780 - learning_rate: 0.0010\n",
            "Epoch 28/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 169.9624 - mae: 9.5616 - rmse: 13.0370 - val_loss: 187.6616 - val_mae: 9.9034 - val_rmse: 13.6990 - learning_rate: 0.0010\n",
            "Epoch 29/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 160.1100 - mae: 9.1885 - rmse: 12.6535 - val_loss: 199.3847 - val_mae: 10.0453 - val_rmse: 14.1204 - learning_rate: 5.0000e-04\n",
            "Epoch 30/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 157.0087 - mae: 9.1229 - rmse: 12.5303 - val_loss: 190.1819 - val_mae: 9.7840 - val_rmse: 13.7906 - learning_rate: 5.0000e-04\n",
            "Epoch 31/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 151.3134 - mae: 8.9925 - rmse: 12.3010 - val_loss: 192.9993 - val_mae: 9.9546 - val_rmse: 13.8924 - learning_rate: 5.0000e-04\n",
            "Epoch 32/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 148.5267 - mae: 8.8594 - rmse: 12.1872 - val_loss: 214.0460 - val_mae: 10.3887 - val_rmse: 14.6303 - learning_rate: 5.0000e-04\n",
            "Epoch 33/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 147.7379 - mae: 8.8203 - rmse: 12.1547 - val_loss: 210.8759 - val_mae: 10.1395 - val_rmse: 14.5216 - learning_rate: 5.0000e-04\n",
            "Epoch 34/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 145.7823 - mae: 8.7999 - rmse: 12.0740 - val_loss: 211.0437 - val_mae: 10.2501 - val_rmse: 14.5273 - learning_rate: 5.0000e-04\n",
            "Epoch 35/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 146.0615 - mae: 8.8022 - rmse: 12.0856 - val_loss: 201.7758 - val_mae: 10.0312 - val_rmse: 14.2048 - learning_rate: 5.0000e-04\n",
            "Epoch 36/120\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 136.4004 - mae: 8.4919 - rmse: 11.6791 - val_loss: 202.7653 - val_mae: 9.9540 - val_rmse: 14.2396 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000215261BF250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000215261BF250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 197ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000215261BF250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000215261BF250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step\n",
            "\n",
            "=========== RESULTADO FINAL – ÚLTIMA JANELA ===========\n",
            "MAE      = 9.62\n",
            "RMSE     = 12.89\n",
            "S-Score  = 295.13\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LSTM RESIDUAL FINAL – HIPERPARÂMETROS OTIMIZADOS (FD001)\n",
        "# Arquitetura oficial + melhores hiperparâmetros da random search\n",
        "# ============================================================\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# FUNÇÃO OFICIAL DA PONTUAÇÃO S (PHM08)\n",
        "# ============================================================\n",
        "def s_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Implementação vetorizada do S-Score da competição PHM08.\n",
        "    Penaliza subestimativas mais fortemente do que superestimativas.\n",
        "    \"\"\"\n",
        "    d = y_pred - y_true\n",
        "    s = np.where(\n",
        "        d < 0,\n",
        "        np.exp(-d / 13) - 1,   # subestimou\n",
        "        np.exp(d / 10) - 1     # superestimou\n",
        "    )\n",
        "    return np.sum(s)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURAÇÕES INICIAIS\n",
        "# ============================================================\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# ============================================================\n",
        "# LEITURA DOS DADOS FD001\n",
        "# ============================================================\n",
        "base = \"CMAPSSData/\"\n",
        "train = pd.read_csv(base + \"train_FD001.txt\", sep=r\"\\s+\", header=None)\n",
        "test  = pd.read_csv(base + \"test_FD001.txt\",  sep=r\"\\s+\", header=None)\n",
        "rul   = pd.read_csv(base + \"RUL_FD001.txt\",   sep=r\"\\s+\", header=None)\n",
        "\n",
        "col_names = [\"unit_nr\", \"time_cycles\", \"setting_1\", \"setting_2\", \"setting_3\"] \\\n",
        "    + [f\"s{i}\" for i in range(1, 22)]\n",
        "train.columns = col_names\n",
        "test.columns  = col_names\n",
        "\n",
        "print(\"Train:\", train.shape, \"Test:\", test.shape)\n",
        "\n",
        "# ============================================================\n",
        "# RUL COM LIMITE (125)\n",
        "# ============================================================\n",
        "rul_cap = 125\n",
        "rul_dict = {i+1: rul.iloc[i, 0] for i in range(len(rul))}\n",
        "\n",
        "def add_rul(df, is_test=False):\n",
        "    df = df.copy()\n",
        "    m = df.groupby(\"unit_nr\")[\"time_cycles\"].max().reset_index()\n",
        "    m.columns = [\"unit_nr\", \"max_cycle\"]\n",
        "    df = df.merge(m, on=\"unit_nr\", how=\"left\")\n",
        "    df[\"RUL\"] = df[\"max_cycle\"] - df[\"time_cycles\"]\n",
        "    if is_test:\n",
        "        df[\"RUL\"] += df[\"unit_nr\"].map(rul_dict)\n",
        "    df[\"RUL\"] = df[\"RUL\"].clip(upper=rul_cap)\n",
        "    df.drop(\"max_cycle\", axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "train = add_rul(train)\n",
        "test  = add_rul(test, is_test=True)\n",
        "\n",
        "# ============================================================\n",
        "# REMOVE SENSORES CONSTANTES\n",
        "# ============================================================\n",
        "const_cols = [c for c in train.columns if train[c].nunique() == 1]\n",
        "train.drop(columns=const_cols, inplace=True)\n",
        "test.drop(columns=const_cols, inplace=True)\n",
        "print(\"Sensores removidos:\", const_cols)\n",
        "\n",
        "# ============================================================\n",
        "# FEATURE ENGINEERING (MEAN5, STD5, SLOPE)\n",
        "# ============================================================\n",
        "def add_features(df):\n",
        "    df = df.copy()\n",
        "    sensor_cols = [c for c in df.columns if c.startswith(\"s\")]\n",
        "    for s in sensor_cols:\n",
        "        df[f\"{s}_mean5\"] = df.groupby(\"unit_nr\")[s].rolling(5, min_periods=1).mean().reset_index(0,drop=True)\n",
        "        df[f\"{s}_std5\"]  = df.groupby(\"unit_nr\")[s].rolling(5, min_periods=1).std().reset_index(0,drop=True).fillna(0)\n",
        "        df[f\"{s}_slope\"] = df.groupby(\"unit_nr\")[s].diff().fillna(0)\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test  = add_features(test)\n",
        "\n",
        "# ============================================================\n",
        "# NORMALIZAÇÃO GLOBAL POR FEATURE\n",
        "# ============================================================\n",
        "feature_cols = [c for c in train.columns if c not in [\"unit_nr\", \"time_cycles\", \"RUL\"]]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
        "test[feature_cols]  = scaler.transform(test[feature_cols])\n",
        "\n",
        "# ============================================================\n",
        "# CRIAÇÃO DAS JANELAS 30\n",
        "# ============================================================\n",
        "def make_sequences(df, window=30):\n",
        "    X, y, units = [], [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "        for i in range(len(feat) - window):\n",
        "            X.append(feat[i:i+window])\n",
        "            y.append(rul[i+window])\n",
        "            units.append(u)\n",
        "    return np.array(X), np.array(y), np.array(units)\n",
        "\n",
        "WINDOW = 30\n",
        "X_all, y_all, units_all = make_sequences(train)\n",
        "\n",
        "# ============================================================\n",
        "# DIVISÃO TEMPORAL 80/20 POR MOTOR\n",
        "# ============================================================\n",
        "unique_units = np.unique(units_all)\n",
        "n_train = int(0.8 * len(unique_units))\n",
        "train_units = unique_units[:n_train]\n",
        "val_units   = unique_units[n_train:]\n",
        "\n",
        "mask_train = np.isin(units_all, train_units)\n",
        "mask_val   = np.isin(units_all, val_units)\n",
        "\n",
        "X_train, y_train = X_all[mask_train], y_all[mask_train]\n",
        "X_val,   y_val   = X_all[mask_val],   y_all[mask_val]\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "\n",
        "# ============================================================\n",
        "# MODELO LSTM RESIDUAL – HIPERPARÂMETROS OTIMIZADOS\n",
        "# ============================================================\n",
        "def build_residual_lstm(n_timesteps, n_features):\n",
        "\n",
        "    inp = layers.Input(shape=(n_timesteps, n_features))\n",
        "\n",
        "    # LSTM 1\n",
        "    x1 = layers.LSTM(96, return_sequences=True)(inp)\n",
        "    x1 = layers.Dropout(0.1)(x1)\n",
        "\n",
        "    # LSTM 2\n",
        "    x2 = layers.LSTM(96, return_sequences=True)(x1)\n",
        "    x2 = layers.Dropout(0.1)(x2)\n",
        "\n",
        "    # Residual\n",
        "    res1 = layers.add([x1, x2])\n",
        "\n",
        "    # LSTM 3\n",
        "    x3 = layers.LSTM(48)(res1)\n",
        "    x3 = layers.Dropout(0.1)(x3)\n",
        "\n",
        "    out = layers.Dense(1, activation=\"relu\")(x3)\n",
        "\n",
        "    model = keras.Model(inputs=inp, outputs=out)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"mse\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        metrics=[\n",
        "            keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "            keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_residual_lstm(WINDOW, len(feature_cols))\n",
        "model.summary()\n",
        "\n",
        "# ============================================================\n",
        "# TREINO FINAL\n",
        "# ============================================================\n",
        "early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
        "reduce = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-6)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=120,\n",
        "    batch_size=32,\n",
        "    callbacks=[early, reduce],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === SALVAR MODELO ===\n",
        "# model.save(\"model.h5\")\n",
        "\n",
        "# === SALVAR SCALER IGUAL AO DO TREINO ===\n",
        "# import joblib\n",
        "# joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# TESTE – ÚLTIMA JANELA\n",
        "# ============================================================\n",
        "def make_test_last(df, window=30):\n",
        "    X, y = [], []\n",
        "    for u in df[\"unit_nr\"].unique():\n",
        "        unit_df = df[df[\"unit_nr\"] == u]\n",
        "        feat = unit_df[feature_cols].values\n",
        "        rul  = unit_df[\"RUL\"].values\n",
        "        X.append(feat[-window:])\n",
        "        y.append(rul[-1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_test, y_test = make_test_last(test)\n",
        "pred = model.predict(X_test).flatten()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "s = s_score(y_test, pred)\n",
        "\n",
        "print(\"\\n=========== RESULTADO FINAL – ÚLTIMA JANELA ===========\")\n",
        "print(f\"MAE      = {mae:.2f}\")\n",
        "print(f\"RMSE     = {rmse:.2f}\")\n",
        "print(f\"S-Score  = {s:.2f}\")\n",
        "\n",
        "# ============================================================\n",
        "# DISPERSÃO\n",
        "# ============================================================\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, pred, alpha=0.5)\n",
        "plt.plot([0,125],[0,125],'r--')\n",
        "plt.xlabel(\"RUL real\")\n",
        "plt.ylabel(\"RUL previsto\")\n",
        "plt.title(\"LSTM Residual – Final (Hiperparâmetros Otimizados)\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
